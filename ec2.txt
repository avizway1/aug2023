=====================================================================================

EC2 : Elastic Compute Cloud : Server class :  Region specific service

CPU, Memory/RAM, Storage/HDD/SDD, Network (wifi, bt, NIC/ENI)

Instance = Server = Azure VM = Compute engine = box

CLient Class OS : Win7, win10
Server Class OS : Windows server 2008 r2, 2012, 2012 r2, 2016, 2019

On-Demand ec2 instances : When we have unpredictable workloads.. Testing our application for the firsttime.. "FREE TIER ELIGIBILITY"
Pricing : /Sec (With min of 60 Sec)

Reserved ec2 instances : When out workload is stable and predictable.. For longer durations.. We can reserve the capacity for 1yr/3yr.. "NO FREE TIER ELIGIBILITY""

	Standard RI : We cannot change config during the period. 
	Convertable RI : We can change/exchange the config during the period.

Pricing : 
Full Upfront : Pay 100% as onetime. 
Partial upfront : Pay 30-50% as onetime, Then remaining amount pay monthly basis with redused hourly price, based on usage.
No upfront : Pay everything monthly basis. 
--> AWS Marketplace : We can sell our resources. 

Spot instances : When we have flexible start/stop durations.. No Criticaldata/ application is delivering..!!  Test env.. 
Bid your price against AWS pricing. If our quoted price is euqual or greater than aws pricing, we will get the instance.
--> high confi server at low cost for temp requ.
"NO FREE TIER ELIGIBILITY"
--> quoted price is euqual or greater than aws pricing, we will get the instance.
--> If price increased, AWS will terminate(delete) our instance.

1 hr 50 Min : Price increased, AWS Terminated our Instance : 1 Hr
1 hr 50 Min : Price not increased, You Terminated our Instance : 1 Hr 50 Min

______________________________________

Instance = Azure VM = GCP Engine = Virtual Machine = Box = Server 


Step 1 : Add Tags

Step 2 : Choose AMI (Windows, Amazon Linux, redhat, suse, ubuntu....)

Step 3 : Instance type (t2.micro) (CPU and Memory)

Step 4 : Create a Keypair (Default Username and password to login)

Step 5 : Network configuration (AZ/PublicIP/What ports you want to open)

Step 6 : Choose Storage options (SSD/HDD/Magnetic)


______________________________________


Only On-Demand ec2 instances comes under free tier eligibility.
** Fix to one region. ap-south-1

Windows ec2 instance launch : 

Step 1 : Choose an AMI (Amazon Machine Image)	: Operating System : Windows server 2016 base

Step 2 : Choose an Instance type 		: vCPU, Memory(RAM), Network perf
==> t2.micro


General Purpose : Stable/balanced performance of compute, memory and network resources.
Type : t2, t3, t4, m5

Compute Optimized : We will get more CPU performances from these instances. We will have high perf processors in these instances.
Type : c4, c5, c6  (Compute / CPU)

Memory Optimized : We will get more RAM perf. Workloads required to process large set of data via memory.
Type : r4, r5, r6, x1, z1, u1 (RAM)

GPU Optimized / Accelerated computing : We will get more graphic processings, Efficient for data pattern matching, High level gaming.
Type : p2, p3, p4, g3, g4, f1

Storage optimized : we will get more Storage/ Hard Disk performance. FOr the application required more IOPS, we use this types.
Type : d2, d3, i3

m5.large	: 2 CPU, 8 RAM
c5.xlarge	: 4 cpu, 8 ram
t4g.medium	: 2 cpu, 4 ram

Maintenance windows : Sat 03 AM IST.. : Greenzone window : CRQ (Change Request)

Step 3 : Configure additional settings
	VPC, ROles, userdata

	Instance Termination protection : Enable (Protect against accidental termination)
	Shutdown behaviour : STOP

Step 4 : Choose storage

	root volume : volume that contains Operating system : 30 gb for windows

Step 5 : Add Tags : COmbination of Key and Value pairs.

Name : 
Project : 
Platform : Windows / Linux
COst center : AAZAA

Step 6: Configure Security Group : Security group acts as Firewall at Instance level.

OS Ports/protocols : 0 - 65535

Windows : RDP : 3389 : 
Linux : SSH : 22
Webserver : http : 80
Secure web : https : 443
mysql : 3306
mssql : 1433
NFS : 2049

source : From where you want to connect to this instance.
MyIP : It picks currently connected network ip address. No one can connect to the server apart from this particular network users.
Custom : We can give any network IPs. 
Anywhere : Anyone with valid credentials can connect to the server. (username and pwd)

Step 7 : Review and launch with keypair.

Keypair : Key pair contains public key and private key. (.pem)

AWS Holds the Public Key. This will be stored in our launched ec2 instances.
Customer/WE holdes the Private key. Used to decrypt/generate the password for initial instance connect.

Public IP : Unique across the globe : Use this to connect to your instance.
Private IP : Unique with in the aws network : 

COnnect to Windows Instance :

--> Open "run" , type "mstsc" , CLick enter.. Provide instance "Public IP".
--> Choose instance "connect', choose "RDP Client", "Download remote desktop file"

MAC : https://apps.apple.com/us/app/microsoft-remote-desktop/id1295203466?mt=12


start/stop : 10 days work.. 1 month.. : Stop, Start the server
Terminate : Delete the server..


Windows : No addl softwares required..  Click on start --> search "remote desktop connection"
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

==> open run (Windows Key + R) --> type "mstsc"
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

==> Select Instance, Click on "connect" and Select "RDP Client", click on "Download remote desktop file", open the downloaded file.


Mac : Goto appstore --> search for "microsoft remote desktop" software.
Computername/ip : provide public IP
Username : Administrator
Pwd : get it using keypair

________________________

Task : Launch windows ec2 instance and using keypair get connect to ec2 instance.

Task 2 : Change the password of "Administrator", Disconnect from the instance. 
Now try to login to ec2 instance using "keypair pwd", "Custom password"../

Task 3 : "Create a new user" with in the ec2 instance and provide him "Local administrator rights", also provide him "Remote desktop permissions".. Take a session with this user along with administrator.

____




AWS @ 9:15 AM (IST) By Mr.Avinash
Day-1 https://youtu.be/1JHp0IL6CUQ
Day-2 https://youtu.be/iyEDo6sE1Dk
Day-3 https://youtu.be/igR86Q8QBlM
Day-4 https://youtu.be/cTZsf_Jt1PA
Day-5 https://youtu.be/hIKKh5H1qZg
Day-6 https://youtu.be/IPxQlLVZUxg
Day-7 https://youtu.be/9Qcvwpk0PPM
Day-8 https://youtu.be/W6ZjibBpimY


======================================================================

D: 04/09/2023


Step 1 : Add some Tags

Step 2 : CHoose a Linux AMI (Amazon Linux)

Step 3 : choose Instance Type (t2.micro)

Step 4 : Choose an Existing keypair / Create a new keypair.

Step 5 : Network Settings
Security group : It acts as firewall at Instance level. 

Linux : SSH (Secure Shell) : Port No : 22

Step 6 : Review and create. 


-----------


How to Connect to Linux Instance :

--> Select Instance, click on "Connect" --> "ec2 instance connect" --> "ec2-user" --> Connect. (We don't use this in realtime)
___

--> We can use windows Cmd prompt to connect to Linux Instance : Install "OpenSSH" in your laptop. 
	--> apps&features --> optional features --> openssh client--> Enable/Install.

==> https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse

==> ssh -i keypair.pem ec2-user@publicip/dns
ssh -i "linuxkp.pem" ec2-user@ec2-3-108-53-198.ap-south-1.compute.amazonaws.com

__

Putty : Putty Don't support .pem format files.. Putty need .ppk (putty private key) file format. 
1 --> generate a .ppk file, before launching linux instance and use the .ppk file to connect using putty application.
2 --> Convert the existing .pem file to .ppk file using PuttyGEN application. 

https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html	--> Download putty

__

Install "GIT for Windows", Then use GIt terminal to connect. 

https://git-scm.com/download/win

--> go to the location where we have the keypair, "Git Bash here"


Bad Permissions error :  chmod 400 keypairname.pem  (Works with GIT for Windows)

https://stackoverflow.com/questions/8193768/unprotected-private-key-file-error-using-ssh-into-amazon-ec2-instance-aws
___________________________

Linux Instances : Default username : ec2-user  / redhat / ubuntu

Task : Launch Linux ec2 instance and get connect to it.

============================================================================================================

D: 05/09/2023

whoami		--> tells us as what user we are working.
sudo		--> allow user to execute the command with root level permissions
sudo su		--> Switch to root user
exit		--> Exit from root user to ec2-user
clear		--> Clears the screen

ls			--> List the files/folders
ls -a		--> List all including hidden files
pwd			--> Print working directory
mkdir		--> Create a Directory/Folder
touch 		--> o bytes file/ plain file
cd			--> Change directory
cd ..		--> To come one step back from current path.
rmdir		--> remove directory, if it is empty.
rm -rf foldername/	--> Delete a directory that contains files

/dev is the location all newly added volumes stores. to navigate cd /dev/ then enter "ls -ll" it shows all directory files properties.

init 6		--> to reboot linux instance
init 0		--> to shoutdown an ec2 instance

copy and paste :  cp
cut and paste  :  mv

to rename a file we use "mv" command :  mv oldfilename newfilename

_________________________

vim / vi / nano

VIM Editor : 

vim filename	--> Open this file in VIM editor
vim test.txt

Press I		--> INSERT Mode
Press ESC		--> ReadOnly Mode
:wq				--> Write and Quit (Write changes to file and quit the editor)
:q!				--> Quit the Editor without writing the changes



=====================================

https://www.udemy.com/course/linuxwithavinash/?couponCode=AUG915AM

=====================================

Task : https://linuxsurvival.com/ (complete atleast 2 modules)

==========================================================================================

D: 06/09/2023

Req: Make this linux Instance as Web Server (Apache).

rpm : Redhat package manager
yum : Yellowdog Update manager

yum install httpd -y
service httpd status			--> httpd webserver service status
service httpd start/stop/restart
chkconfig httpd on				--> Makes httpd as logon service.

path : /var/www/html/

cd /var/www/html/

Apache defaultly runs on port 80, if you want to change to diff port, we need to modify the httpd.config file. Change listen option, Make sure you restart httpd service.
--> Open required port number in security group.


Tool to Move the files to amazon linux ec2 instance : WinSCP

--------

Task 1 : Launch an amazon linux 2, make it as webserver and deliver custom web content.

Task 2 : Launch an Amazon Linux 2, install nginx and deliver custom web page.


EIP / Elatic IP Address : With the help of EIP, we can give a static public ip address to our ec2 instance.
--> If you perform stop & start, this EIP wont change.

==> We cannot change instance type when it is in running state. 
We should stop instance to perform upgrade/downgrade.

===========================================================================

D: 07/09/2023

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html

How to deal with Volumes

root volume : COntains OS : gp2,gp3, io1, io2 and magnetic

IOPS : Input and output Operations per second

GP2, Gp3 : general Purpose :SSD: Suitable for most of the common workloads.
io1, io2 : Provisional IOPS :SSD: Gives best perf am,ong all storage options. 
sc1 ($), st1($$) : HDD : wont support boot : Best throughput values. : log processing/bigdata
magnetic : standard : We dont use this.. : Cheapest storage 

Windows : FAT, NTFS and ReFS
Linux : ext3, ext4, xfs

EBS : Elastic Block Storage : Block based storage : Designed to run OS.. 

root : SSD and magnetic is supported.
Addl volume : SSD, HDD and magnetic


Step 4 : CHoose Storage

--> EBS : Elastic Block Storage
SSD / HDD / Magnetic


root Volume : COntains OS : gp2, gp3, io1, io2 and standard/magnetic
Additional volume : all root supported + st1, sc1

General Purpose SSD : (gp2 / gp3) : Low latency interactive applications, Dev and test environment..!!
Min : 1 GiB, Max: 16 TiB... Max IOPS: 16,000 IOPS
gp2 --> works 1 : 3 ration (1 gb volume = 3 iops), with min of 100..

for gp3, we have an advantage, we can mention/choose required IOPS count.

__

Provisioned iops : (io1 & io2) : workload that requires Specific IOPS count.. or if we need more than 16,000 iops for our ec2 instance.. I/O Intensive database workloads..
Min : 4 GiB, Max: 16 TiB... Max IOPS: 64,000 IOPS
--> It provided highest performance among all. 

io2 Block Express volume : Min : 4 GiB, Max: 64 TiB...
Supports 256,000 IOPS.. 
__

Magnetic : Standard : Less freq accessed data, Low cost storage solutions.. 
Min : 1 GiB, Max: 1 TiB...
__

Throughput optimized HDD : st1 : Bigdata, Data warehousing, log processing.. 
Size : Min 125 GiB - 16 TiB.. IOPS : 500.. Throughput : 500 MB/S..

Cold HDD : sc1 : THroughput orientes storages, but with Less Frequently accessed.. Lower cost than st1.. 
Size : Min 125 GiB - 16 TiB.. IOPS : 250.. Throughput : 250 MB/S..


Free Tier : 30 gb Gp2 and standard storage.. 

--> 20% of volume size (or) 5 gb.. WHichever is highest

** Need to perform OS level operations to make additional volumes available.
--> Disk Management --> diskmgmt.msc --> choose volume --> make it online --> Initilize disk --> SImple volume --> NTFS/FAT --> Create


Windows : FAT, FAT32, NTFS, ReFS
Linux : ext3, ext4, xfs


grab the name of new volume : /dev/xvdb

lsblk		--> List block based devices
df -Th		--> List the available volumes

/dev/xvda1	--> root volume (/)
/dev/xvdf	--> new Volume name --> ##this is the volume name that attached to my instance.

In windows OS, we mount new volumes to drive letters.. But in Linux OS, We mount volumes to Directory. 

mkdir newvolume

file -s /dev/xvdf  	

--> If this command returns with "data", no file system.
--> If this returns ext3/xfs filesystem.. We have a file system.

mkfs -t xfs /dev/xvdf		--> Make file system and write it to Additonal volume

mount /dev/xvdf newvolume/	--> mount addl volume to directory

=================

--> Above mount is temp mount only.. it won't available after the instance reboot.
--> To make this volume perm mount to the directory, Add entry in "/etc/fstab" file.
--> Get the entry information from "/etc/mtab" file. 

--> cat /etc/mtab		--> Grab the entry related to newly added addl volume

example entry : /dev/xvdb /home/ec2-user/newvolume xfs rw,relatime,attr2,inode64,noquota 0 0

--> vim /etc/fstab.. Write the above entry, save and quit the editor. (Do not edit the existing entry).

mount -all
__________

--> Increase the volume size the "Cosole" first, then execute the below command..!!

We can use "xfsprogs" to increase existing volume size. 

yum install xfsprogs

--> xfs_growfs -d /volume-Mountpoint
--> xfs_growfs -d /home/ec2-user/newvolume


===========================================================================

--> Increasing volume is possible, But redusing volume is not possible.

=============================================================================

Task : Launch an ec2 instance, Create a 1gb volume, associate it with ec2 instance.. Make 1 gb volume available at os level and write some data into it. (Reboot and verify)
df -Th after reboot, also should show 1gb volume.

Task 2 : Launch another ec2 instance in same AZ as existing ec2 instance (task 1 instance).. Detach the volume from instance 1 and attach it to newly launched ec2 instance. You should be able to see all the data.


Task 3 : Launch a Windows ec2 instance, Create a 2 gb volume, associate it with ec2 instance.. Make 2 gb volume available at os level and write some data into it. (Reboot and verify). 

-- : Possible with your own aws accounts.

Task 4 : Add 2 more gb size to Task 3 Volume and extend volume at OS level.


==========================================================================================

D: 08/09/2023

Instance 1 in ap-south-1a ---> Instance 2 in ap-south-1a ==> Detach from instance 1 and attach to instance 2.. 

Instance 1 in ap-south-1a ---> Instance 2 in ap-south-1b ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff AZs.. 
Choose the volume --> Take a Snapshot --> Create a volume from snapshot, while creating choose ap-south-1b --> we'll get volume in 1b --> Attach to Instance 2 running in ap-south-1b

Instance 1 in Mumbai : ap-south-1a ---> Instance 2 in N Virginia : us-east-1a ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff regions.. 
Choose the volume --> Take a Snapshot --> Copy the snapshot to desired region (NV) 
--> Create a volume, while creating choose us-east-1a --> volume in 1a --> Attach to Instance 2 running in N Virginia : us-east-1a.
(Data transfer from region to region cost us)


Instance 1 in AWSACC1 : Mumbai : ap-south-1a ---> Instance 2 in AWSACC2 : Mumbai : ap-south-1a ==> Detach from instance 1 and attach to instance 2 is not possible as both are running in diff aws accounts, regions.. 
Choose the volume --> Take a Snapshot --> share the snapshot to another aws account 
--> Create a volume, while creating choose ap-south-1a in acc2

Instance 1 volume need to share with everyone.. --> Create a snapshot --> Share to "Public" --> 


MultiAttach : https://www.youtube.com/watch?v=2j8R3ajSo3s

** We cannot decrease the size of an EBS volume. Only increase is possible.
EBS VOlumes : Always use EBS volumes only.


Snapshot : Backup copy of an EBS volume.

https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/


--> Snapshots are point-in-time copies.
--> Snapshots stores in S3 platform (Not in your s3).
--> Can we view what data we have inside snapshots..?? NO
--> Snapshot Works with Incremental backup mechanism.
--> If our volume is Encrypted, Snapshot also Encrypts automaticALLY. 
--> When we are launching/creating a volume from encrypted snapshot, volume also encrypts automatically.
--> We cannot share an Default Master key Encrypted snapshot.
--> If we are using Custom encryption key, we can share snapshot with another aws account, but we need to provide permissions on encryption key also to another aws account.

--> How can we encrypt an existing un-encrypted volume.
Ans ; Create a snapshot of un-encry volume, then create a volume from that snapshot, enable Encry while creating.

============================================================================================

DLM : Data lifeCycle Management : Designed to automate the snapshot /AMI creation.

With the help of TAGs we can filter the resources.
--> Resource : We can configure for "Volumes" or "Entire ec2 instance" or "exclude root volume".


key=Backup-Schedule 
Value=prd/uat/dev
Value = schedule-1
value = daily

-----

SOP : Standard Operational Procedure : 

DLM : Data Lifecycle manager : Automate the snapshot creation process. 
--> We use "tags" to filter the resources. 

Default Retention Values: 
Prod : 7 Days
Non Prod : 3 Days 

Fast snapshot restore : Enable fast snapshot restore to ensure that volumes created from snapshots created by this policy instantly deliver all of their provisioned performance.


Task : https://aws.amazon.com/blogs/storage/automating-amazon-ebs-snapshot-and-ami-management-using-amazon-dlm/

__________


Task 1 : Launch an ec2 instance in ap-south-1a.. Create a "New volume with 1 gb size" in ap-south-1a and attach this volume to ec2 instance and make it available and write some data. Goto AWS console "Increase the volume size to 2 GB", make this 2gb volume available at OS level. Write some data.

Task 2 : Launch Another ec2 instance in ap-south-1b..
Get the 2gb volume data from instance 1a to newly launch 1b ec2 instance.. Make Same volume available to "1b instance"..!!

=====================================================================================

D: 09/09/2023

Scenario : 10 ec2 instances.. AV, MS Office, Custom WP, CUstom OS users, Applications, IIS.. 

--> Launching 10 instance : connect to 10 instance and install everything in all 10 instance.. 
--> 1 ec2 instance : Install everything.. : Keep it as Image : --> Launch "n" number using image..

Client : OS with CIS Benchmarks (Center for Internet Security) : 

*** GoldenAMI = CUstomized AMI.. For WINDOWS : Won't work with keypairs.. We need to change the password.. 

Ec2 instance , Perform customizations --> Create a Golden AMI --> From GAMI we can launch 'n' num of ec2 instance.. 

Similar to Snapshots..

--> We can launch another instance in same region using GAMI.
--> We can copy Region 1 GAMI to Region 2, And launch an ec2 instance in Region 2. 
--> We can share GAMI from Acc 1 to Acc 2. 
--> We can share GAMI to public.

______________________________________


How to recover a Linux ec2 instance, if we lost keypair.?
--> Select the instance, Create a GoldenAMI, Launch new Instance from GAMI, While launching create a new keypair..!! Now youn can use new keyapir to connect to instance. 

For windows instances, we need to depend on SSM (systems manager - runcommand and parameter store) to recover password.

______________________________________


Task 1 : Launch Linux ec2 instance, Make it as webserver.. Add custom webpages.. Create a 2gb volume and associate it make it perm mount and write some data.. then Create a Golden AMI and Launch instance from GAMI and test output. 

Task 2 : Launch a Windows ec2 instance, Connect to it.. CHANGE ADMINISTRATOR PASSWORD, change timezone, change wallpaper, install "putty" software, Install IIS and deliver custom webpage..
Now, STOP the INSTANCE and create a GoldenAMi. Launch an instance from GAMI, connect and Verify you got all custom settings or not.???

Task 3 : How to setup password authentication to ec2-user user instead of keypair authentication.
https://comtechies.com/password-authentication-aws-ec2.html

Task 4 : launch a linux ec2 instance, Delete the keypair and try to connect to it.!! Fails..
Now, create a goldenAMI, while launching "NEW KEYPAIR", and try to connect.

Task 5 : Launch a new ec2 instance and configure alarm to stop ec2 instance when cpu usage is less than 20% for 5 minutes, also configure to receive alerts when alarm triggers.


============================================================================================

D: 11/09/2023

--> Cloud watch : Service to monitor all AWS resources i.e; s3, ec2, rds.. 
--> We can monitor CPU, Disk and network for ec2 instance.
** With Default metrics, we cannot monitor MEMORY Utilisation. 
--> We can install an CloudWatch agenet and monitor Memory usage aswell. 

--> We have two types of monitorings in AWS.
==> Basic Monitoring : Free, Enabled by defaultly. 5 Minutes is monitoring interval.
==> Detailed Monitoring : COST US, Need to enable explicitlty, 1 minute is monitoring interval.

Vertical Scaling : Upgrading / Adding more resources to same Instance. i.e; from t2.micro to t3.medium

To perform vertical scaling in AWS, First stop the ec2 instance, then only we can upgrqade it.


#!/bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
echo "<h1>This is my first webserver</h1>" > /var/www/html/index.html


#!/bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
echo "<h1>This is my Second webserver</h1>" > /var/www/html/index.html

-----

EIP : Dedicated Public IPm address for our ec2 instance.

ENI : Elastic network Interface : Additional NIC card for ec2 instance

----

Task : Create a cw dashaboard and add ec2 instance cpu usage, network in and s3 bucket metrics (no of obj & bucket size).

Task 2 : Try to deliver the webpage with the help of Userdata.


____________________________________________________________________________________


Vertical Scaling : Upgrading same instance resources.. t2.micro --> c5.2xlarge
Horizantal Scaling : Distribute application load to multiple ec2 instances.. 

Classic ELB : Layer 4/7 LB.. : Outdated.. : http, https, tcp, udp.. 
Application ELB : Layer 7 ELB.. : http and https
Network ELB : Layer 4 ELB.. : TCP, UDP, TLS 
Gateway ELB : GENEVE / 3rd party security virtual applicances.. 

**Please select at least two Subnets in different Availability Zones to provide higher availability for your load balancer.

** Dont use same Security group for your ec2 instance and Load balancer.


For ELBs, We will get DNS Endpoint..
Roundrobin algorithm.. 

If you want to view IP address of an ELB, 
--> Navigate to "Network interfaces" and observe, You can get IP of ELB.
--> nslookup "ELB-DNS-NAME"
___________________________________________________

Target Group : Each target group is used to route requests to one or more registered targets. When you create each listener rule, you specify a target group and conditions. When a rule condition is met, traffic is forwarded to the corresponding target group.

Application ELB : http and https

Application Load balancing algorithm : 
--> Round robin
--> Least outstanding requests

--> We cannot assign a dedicated IP address for our Application ELB.

Network ELB : TCP.. 
--> Flow Hash algorithm.
--> We CAN assign a dedicated IP address for our network ELB.

Application LB Supports path based routing, also supports Microservices.

millions req/sec : NLB

ELB Access Logs : Logging on ELB. Destination is s3.
_________________________

Free Tier : 750 hrs/month

-----------------------

Task : Create alb, and deliver webpapes on port 80, 8888, 8080. 


--> what is telnet and how to use telnet, test it with an ec2 instance on port 22.






==================================================================================


Task : Create nlb, and deliver webpapes on port 80, 8888, 8080. 

Task 2 : Configure pipeline mechanism between ec2 instances and elb.
--> Edit your ec2 instance security group and open port 80 for ELB SG

--> When we give direct instance IP, it should not deliver any webpage.
--> When we give elb dns name, this should work.


Task 3 : Create an Alarm on our ec2 instance. Whever CPU usage is more than 80%, configure to Stop ec2 instance.

Task : Try "stress" command to put load on ec2 instance and test high usage.

stress --cpu 1 --timeout 900

To knnow CPU count run this command: nproc

--> Install stress package first, 
amazon-linux-extras install epel -y
yum install stress -y


=============================================================================================

D: 13/09/2023


1. Create a goldenAMI (Make it as webserver)
2. Create an ELB.  (Create an empty load balancer)
3. Create an ASG
	3.1 Create a Launch teamplate (Settings of new ec2 instances : AMI, Instance type, sg, keypair)
	3.2 create an ASG (when to scale)

________

1 : Create a Golden AMI
2 : Create a ELB
3 : Create a Launch template
4 : Create an ASG with Fixed (2) and test it
5 : Confiure Scheduled scaling.
6 : Configure Simple scaling (low usage scaling)
7 : Configure Versions for Launch Tempplate. 
-----

ASG : Auto Scaling Group :

--> DYnamic (Step/Simple/TargetTracking) Load 
--> Scheduled scaling : 
--> Manual : 


ScaleIN : Remove the instance from ASG
ScaleOut : Add the instances to ASG.

How ASG will choose the instance to terminate if any ScaleIN action triggered..!! 

ASG Termination policy : refer to the image.


t2.micro --> Current configuration.. 
t2.nano..??? How you can do this with 0 downtime..!! 


Create a new launch configuration/template.. Associate this with ASG. Terminate the existing instance.. Now new instance will come with updated launch config settings.
(Set Desired capacity to 2)..!!! 



=============================================================================================

D: 14/09/2023

EFS : Elastic File System : File Share : Shared Storage solution for Multiple ec2 instances. : 
--> Network File System : NFS v4.1 : Port 2049
--> Support only Linux OS 
--> No Pre Provisioning required.
--> Add entry in "/etc/fstab" file.  Get entry info from "/etc/mtab" file

mkdir instance1

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-04f2e91cd10982b8c.efs.ap-south-1.amazonaws.com:/ **mountpoint**

sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-04f2e91cd10982b8c.efs.ap-south-1.amazonaws.com:/ /var/www/html/

==> For windows OS we can use FSx, Works with SMB Protocol (Server message block)

_______________________________________________________________________________________

--> Create a security group and open NFS protocol. 
			--> Open for entire VPC IP address
			--> Open for ec2 instance private IP addresses
			--> Open for everyone (not recommended)
		** --> Open for ec2 instance Security group (pipeline mechanism)



Task : Create EFS and Mount it to multiple ec2 instances. Verify by creating some data in that mopunt points.

Task : Launch an ec2 instance, connect to it, Create EFS.. Install httpd in your ec2 instance.. Mount EFS to /var/www/html/ and create index.html... make that EFS mount permanent. 
==> Now create a GOLDENAMI.. 
==> Configure ASG with this GOLDENAMI.. COnnect to any of the ec2 instance, modify the content.. this modification should reflect in all instance.. 

============================================================================================



Plecement Groups : 
--> Cluster PG
--> partition PG
--> Spread PG

https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html

_______________________________________________________________________________________

Eventbridge : 

--> Event Driven process
--> Scheduled process
--> Trigger both

 Event Bridge : 

 {"version":"0","id":"eec4eda2-6639-e7b3-150d-c6461f1f0686","detail-type":"EC2 Instance State-change Notification","source":"aws.ec2","account":"501170964283","time":"2022-04-08T02:59:33Z","region":"ap-south-1","resources":["arn:aws:ec2:ap-south-1:501170964283:instance/i-00f56eba78b7b4e65"],"detail":{"instance-id":"i-00f56eba78b7b4e65","state":"stopped"}}

 Sample Event : 

 INPUT PATH:

 {"instance-id":"$.detail.instance-id", "state":"$.detail.state", "time":"$.time", "region":"$.region", "account":"$.account"}

 INPUT TEMPLATE: 

 "At <time>, Status of your EC2 instance <instance-id> in the AWS Region <region> has changed to <state>."

----

 https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/ScheduledEvents.html
 https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html#eb-cron-expressions


Task 1 : Configure Eventbridge to stop an ec2 instance at a particular time using Crontab. (10:10 AM)

Task 2 : Configure to stop an ec2 instance after 5 minutes, trigger an email with custom email format.

Optional Task 3 : Configure to get an alert when someone deleted an s3 bucket / someone deleted data from specific s3 bucket.
--> You need to configure Cloudtrail data events for the s3 buckets.

=========================================================================================


ElasticBeanstalk : It provides preconfigured platforms.
--> Python, java, go, ruby, php, .net
--> We can deploy/upload our code to this platform. 
--> AWS Creates ELB, ASG automatically for our instances.
--> Less customisations at OS level, We cannot deliver multiple applications. 
--> it comes under PaaS (Platform as a Service)

--> If any customer/client dont want to manage infra to deliver their application, we can suggest beanstalk.


==========================================================================================

D: 16/09/2023

AWS CLI : 

IAM User : programatic Access : AccesskeyID and SecretAccesskey : AWS CLI.. 3rd, cdk/sdk

https://aws.amazon.com/cli

aws --version			--> Tells us what cli version is installed.

configure the aws cli: aws configure

aws servicename commands

aws s3 ls			--> List all the s3 buckets
aws s3 ls s3://avinash.bucket	--> list objects from the s3 bucket
aws s3 ls avinash.bucket

aws s3 cp/sync sourcepath destinationpath

aws s3 mb s3://avinash.bucket.1 --region ap-south-1

aws s3 cp s3://avinash.bucket s3://avinash.bucket.1 --recursive

aws s3 sync s3://avinash.bucket s3://avinash.bucket.1

presign

aws s3 presign s3://bucketname/objectname --expire 60

aws s3 presign s3://avinash.bucket.1/s3.txt --expire 30


aws ec2 stop-instances --instance-ids i-0d518c0180eb4eba1

___

https://docs.aws.amazon.com/cli/latest/reference/

__
https://awsclibuilder.com/home

___

--profile : We can access multiple AWS accounts from cli using profile option.

Credentials path in windows : C:/users/yourusername/.aws/ Enable Hidden directory view, 

____________________________


Task : Launch an ec2 instance using CLI.  (ami id, instance-type, subnet-id, security group id, keypair, count)


Task 2 : Create an IAM role to allow S3ReadOnlyACcess, associate it to a new ec2 instance. COnnect and test it.   It should not allow you to create a bucket/upload anything.

Now create a new role, associate "S3FullAccess" and replace the existing role and test uploading objects again.


Optinal for Fresher and Mandatory for Exp guys.

Task 3 : Mount an s3 bucket to ec2 instance.
Help Link : https://www.youtube.com/watch?v=GSsrnnU9JLw

Task 4 : Create a role to roam across multiple AWS accounts (using switch role).
Help Link : https://www.youtube.com/watch?v=sZiiB4yF0VY


Saved for later:

Task  : Create a simple index.html and Upload it to an s3 bucket.. while launching the instance, make your instance as webserver with the help of Userdata.. then copy all the webcontent from s3 bucket to web content path (/var/www/html/). Perform using "userdata".

#!/bin/bash
yum install httpd -y
service httpd start
chkconfig httpd on
copy data from s3 to ec2		(--recursive)...?????

==========================================================================================

D : 19/09/2023

Systems Manager run command :
--> All instance must associated with "SSM ROle". 
--> OS level, Every instance have an SSM agent.  
--> Using Tags, We can filter the instances. / We can choose instances manually. 


Task : How to recover a Windows instance administraor password if we loss the keypair.
AWSSupport-RunEC2RescueForWindowsTool

--> Launch a Windows ec2 instance, connect to it, Change ADministrator Password. then Forgot that password.
Now you need to login to this instance.!!


Task : Make linux ec2 instance as webserver without logging to OS level.

Task : Change the timezone of an windows ec2 instance using ssm run command. (tzutil /s "India Standard Time")

======================================

Platform : Windows - WIN
Platform : Linux - LNX
		
[OS]
[Clinet]
[Project/application]
[Environment]
[Number]


OS : Windows - WIN, Linux - LNX
Client : varies : ABC / XYZ
Project/App : varies : MOnitoring / db / web / app 
Enviornment : sandbox / dev / sqa / sit / uat / prd
Number - 01 / 02 / 001 /002

WIN-BOA-DBS-PRD-002

==========================================================================================


Instance store volumes : We don't use this in real environments.   (NO FREE TIER ELIGIBILTY)
	--> Also called as Ephemeral storages (Temporary storage).
	--> We cannot STOP/Start the instance.
	--> Storage will be delivered from underlying host/physical resources.
	--> If required, we can reboot. We don't loss any data.
	--> If underlying h/w failure happens, we'll loss all the data.

________________________

Instance Isolation : https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRjr993FsAyS65uL4QPbGu8n_JcB6Fwq6jDylWglIapsQQjHfbcbir83OT-I-_a-nhvvo8&usqp=CAU

Dedicated and Shared tenancy :
--> Shared tenancy : underlying hardware shared with multiple customers.
--> Dedicated tenancy:
	--> Dedicated instance : Dedicated instance provided by aws. No control on backend process.
	--> Dedicated host : We can apply licenses at underlying physical resources. Also, we can launch multiple instances on a dedicated host.







